{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bd054a5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d10953d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# AML FINAL PROJECT - TABULAR MODELS (TM2)\n",
    "# Final clean version: translated CSV, no translation step\n",
    "# ============================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    cohen_kappa_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c487541",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1acc2b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Helper evaluation functions\n",
    "# ============================================\n",
    "\n",
    "def quadratic_weighted_kappa(y_true, y_pred):\n",
    "    return cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")\n",
    "\n",
    "def evaluate_model(name, y_true, y_pred, verbose=True):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    macro_f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    qwk = quadratic_weighted_kappa(y_true, y_pred)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\n=== {name} ===\")\n",
    "        print(f\"Accuracy   : {acc:.4f}\")\n",
    "        print(f\"Macro F1   : {macro_f1:.4f}\")\n",
    "        print(f\"QWK        : {qwk:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"accuracy\": acc,\n",
    "        \"macro_f1\": macro_f1,\n",
    "        \"qwk\": qwk\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d6d758",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16638740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11565, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1Name</th>\n",
       "      <th>Breed2Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1Name</th>\n",
       "      <th>Color2Name</th>\n",
       "      <th>Color3Name</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>FurLength</th>\n",
       "      <th>...</th>\n",
       "      <th>VideoAmt</th>\n",
       "      <th>Description</th>\n",
       "      <th>PetID</th>\n",
       "      <th>PhotoAmt</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "      <th>FinalBreed</th>\n",
       "      <th>ColorDiversity</th>\n",
       "      <th>Fully_Healthy</th>\n",
       "      <th>lang</th>\n",
       "      <th>Description_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Tabby</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Black</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Nibble is a 3+ month old ball of cuteness. He ...</td>\n",
       "      <td>86e1089a3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>Nibble is a 3+ month old ball of cuteness. He ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Domestic Medium Hair</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Black</td>\n",
       "      <td>Brown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>I just found it alone yesterday near my apartm...</td>\n",
       "      <td>6296e909a</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>I just found it alone yesterday near my apartm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Brown</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Their pregnant mother was dumped by her irresp...</td>\n",
       "      <td>3422e4906</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>Their pregnant mother was dumped by her irresp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Black</td>\n",
       "      <td>Brown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Good guard dog, very alert, active, obedience ...</td>\n",
       "      <td>5842f1ff5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>Good guard dog, very alert, active, obedience ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mixed Breed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Black</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>This handsome yet cute boy is up for adoption....</td>\n",
       "      <td>850a43f90</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>This handsome yet cute boy is up for adoption....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type  Age            Breed1Name Breed2Name  Gender Color1Name Color2Name  \\\n",
       "0     2    3                 Tabby        NaN       1      Black      White   \n",
       "1     2    1  Domestic Medium Hair        NaN       1      Black      Brown   \n",
       "2     1    1           Mixed Breed        NaN       1      Brown      White   \n",
       "3     1    4           Mixed Breed        NaN       2      Black      Brown   \n",
       "4     1    1           Mixed Breed        NaN       1      Black        NaN   \n",
       "\n",
       "  Color3Name  MaturitySize  FurLength  ...  VideoAmt  \\\n",
       "0        NaN             1          1  ...         0   \n",
       "1        NaN             2          2  ...         0   \n",
       "2        NaN             2          2  ...         0   \n",
       "3        NaN             2          1  ...         0   \n",
       "4        NaN             2          1  ...         0   \n",
       "\n",
       "                                         Description      PetID  PhotoAmt  \\\n",
       "0  Nibble is a 3+ month old ball of cuteness. He ...  86e1089a3       1.0   \n",
       "1  I just found it alone yesterday near my apartm...  6296e909a       2.0   \n",
       "2  Their pregnant mother was dumped by her irresp...  3422e4906       7.0   \n",
       "3  Good guard dog, very alert, active, obedience ...  5842f1ff5       8.0   \n",
       "4  This handsome yet cute boy is up for adoption....  850a43f90       3.0   \n",
       "\n",
       "   AdoptionSpeed FinalBreed  ColorDiversity Fully_Healthy lang  \\\n",
       "0              2          0               2             0   en   \n",
       "1              0          0               2             0   en   \n",
       "2              3          3               2             0   en   \n",
       "3              2          3               2             0   en   \n",
       "4              2          3               1             0   en   \n",
       "\n",
       "                                      Description_en  \n",
       "0  Nibble is a 3+ month old ball of cuteness. He ...  \n",
       "1  I just found it alone yesterday near my apartm...  \n",
       "2  Their pregnant mother was dumped by her irresp...  \n",
       "3  Good guard dog, very alert, active, obedience ...  \n",
       "4  This handsome yet cute boy is up for adoption....  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================\n",
    "# 1. Load translated training data\n",
    "# ============================================\n",
    "\n",
    "# Use your actual translated filename here:\n",
    "df = pd.read_csv(\"train_fe_english.csv\")  # or whatever it's called\n",
    "\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d01513",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "918df46b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description_en</th>\n",
       "      <th>desc_length</th>\n",
       "      <th>sentiment_vader</th>\n",
       "      <th>positive_kw</th>\n",
       "      <th>negative_kw</th>\n",
       "      <th>keyword_sentiment</th>\n",
       "      <th>keyword_sentiment_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nibble is a 3+ month old ball of cuteness. He ...</td>\n",
       "      <td>359</td>\n",
       "      <td>0.9552</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I just found it alone yesterday near my apartm...</td>\n",
       "      <td>118</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Their pregnant mother was dumped by her irresp...</td>\n",
       "      <td>393</td>\n",
       "      <td>0.7650</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good guard dog, very alert, active, obedience ...</td>\n",
       "      <td>146</td>\n",
       "      <td>0.9538</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This handsome yet cute boy is up for adoption....</td>\n",
       "      <td>390</td>\n",
       "      <td>0.9880</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.005115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Description_en  desc_length  \\\n",
       "0  Nibble is a 3+ month old ball of cuteness. He ...          359   \n",
       "1  I just found it alone yesterday near my apartm...          118   \n",
       "2  Their pregnant mother was dumped by her irresp...          393   \n",
       "3  Good guard dog, very alert, active, obedience ...          146   \n",
       "4  This handsome yet cute boy is up for adoption....          390   \n",
       "\n",
       "   sentiment_vader  positive_kw  negative_kw  keyword_sentiment  \\\n",
       "0           0.9552            1            1                  0   \n",
       "1           0.1280            0            0                  0   \n",
       "2           0.7650            2            0                  2   \n",
       "3           0.9538            0            0                  0   \n",
       "4           0.9880            2            0                  2   \n",
       "\n",
       "   keyword_sentiment_norm  \n",
       "0                0.000000  \n",
       "1                0.000000  \n",
       "2                0.005076  \n",
       "3                0.000000  \n",
       "4                0.005115  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================\n",
    "# 2. TEXT FEATURES: VADER, KEYWORDS, LENGTH\n",
    "# ============================================\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Ensure Description_en exists and is string\n",
    "if \"Description_en\" not in df.columns:\n",
    "    # Fallback: if somehow missing, just copy Description\n",
    "    df[\"Description\"] = df[\"Description\"].fillna(\"\").astype(str)\n",
    "    df[\"Description_en\"] = df[\"Description\"]\n",
    "else:\n",
    "    df[\"Description_en\"] = df[\"Description_en\"].fillna(\"\").astype(str)\n",
    "\n",
    "# Description length\n",
    "df[\"desc_length\"] = df[\"Description_en\"].str.len()\n",
    "\n",
    "# VADER sentiment (compound)\n",
    "df[\"sentiment_vader\"] = df[\"Description_en\"].apply(\n",
    "    lambda x: analyzer.polarity_scores(x)[\"compound\"]\n",
    ")\n",
    "\n",
    "# Keyword features\n",
    "positive_keywords = [\n",
    "    \"friendly\",\"playful\",\"sweet\",\"gentle\",\"nice\",\"calm\",\n",
    "    \"good with kids\",\"good with children\",\"affectionate\",\"loving\",\n",
    "    \"healthy\",\"vaccinated\",\"obedient\"\n",
    "]\n",
    "\n",
    "negative_keywords = [\n",
    "    \"fearful\",\"aggressive\",\"bite\",\"biting\",\"sick\",\"injured\",\n",
    "    \"old\",\"anxious\",\"shy\",\"timid\",\"problem\",\"issue\"\n",
    "]\n",
    "\n",
    "def count_keywords(text, keywords):\n",
    "    t = text.lower()\n",
    "    return sum(1 for kw in keywords if kw in t)\n",
    "\n",
    "df[\"positive_kw\"] = df[\"Description_en\"].apply(lambda x: count_keywords(x, positive_keywords))\n",
    "df[\"negative_kw\"] = df[\"Description_en\"].apply(lambda x: count_keywords(x, negative_keywords))\n",
    "\n",
    "df[\"keyword_sentiment\"] = df[\"positive_kw\"] - df[\"negative_kw\"]\n",
    "df[\"keyword_sentiment_norm\"] = df[\"keyword_sentiment\"] / (df[\"desc_length\"] + 1)\n",
    "\n",
    "df[[\n",
    "    \"Description_en\",\n",
    "    \"desc_length\",\n",
    "    \"sentiment_vader\",\n",
    "    \"positive_kw\",\n",
    "    \"negative_kw\",\n",
    "    \"keyword_sentiment\",\n",
    "    \"keyword_sentiment_norm\"\n",
    "]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7857ca0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3b9c77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7e339d16d9e469b849f1674718edc94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\conno\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\conno\\.cache\\huggingface\\hub\\models--sentence-transformers--clip-ViT-B-32. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be60dd6c073465993229dcfe944d13a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a753499f30148699f81e69e668307e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d612e75e909e42b598b5defc8a365d33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b031cb205c754d3c8ea1a5cdfc65d76e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/604 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cc44ee9f7874311ac8d1cb8d54636a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "235ed9ab3131424fa6c831ec0d987e8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45ea47cf6c0044d88591e8b6d5e8d994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3441eaeebf94e07a5aabd4ebce8e81f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62c5a9ed1ade41759c738975e2b503df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/605M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec14378dfe084e1db83d174dc4bc4463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/605M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4895463a612e4b75a1705b504060ed74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/362 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw CLIP text embeddings shape: (11565, 512)\n",
      "PCA-reduced CLIP text shape: (11565, 50)\n",
      "DF shape after adding CLIP text PCA features: (11565, 82)\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 3. TEXT EMBEDDINGS: CLIP TEXT ENCODER ON Description_en + PCA\n",
    "# ============================================\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Use a CLIP-based text encoder from sentence-transformers\n",
    "# You can try:\n",
    "#   \"clip-ViT-B-32\" (512-d)\n",
    "#   \"clip-ViT-L-14\" (768-d, heavier)\n",
    "clip_model = SentenceTransformer(\"clip-ViT-B-32\")\n",
    "\n",
    "# Make sure we have clean English descriptions\n",
    "descriptions_en = df[\"Description_en\"].fillna(\"\").astype(str).tolist()\n",
    "\n",
    "# Get CLIP text embeddings\n",
    "clip_text_embeddings = clip_model.encode(\n",
    "    descriptions_en,\n",
    "    show_progress_bar=True\n",
    ")   # shape: (n_samples, 512) for ViT-B-32\n",
    "\n",
    "print(\"Raw CLIP text embeddings shape:\", clip_text_embeddings.shape)\n",
    "\n",
    "# PCA → 50 components (you can tune this)\n",
    "pca_components = 50\n",
    "pca = PCA(n_components=pca_components, random_state=42)\n",
    "clip_text_pca = pca.fit_transform(clip_text_embeddings)\n",
    "\n",
    "clip_pca_df = pd.DataFrame(\n",
    "    clip_text_pca,\n",
    "    columns=[f\"clip_text_pca_{i}\" for i in range(pca_components)]\n",
    ")\n",
    "\n",
    "print(\"PCA-reduced CLIP text shape:\", clip_pca_df.shape)\n",
    "\n",
    "# Merge CLIP PCA features into main df\n",
    "df = pd.concat([df.reset_index(drop=True), clip_pca_df], axis=1)\n",
    "\n",
    "# Remove any duplicate columns just in case\n",
    "df = df.loc[:, ~df.columns.duplicated()]\n",
    "\n",
    "print(\"DF shape after adding CLIP text PCA features:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88baf0b6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b17d887c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final X shape: (11565, 71)\n",
      "First 20 feature columns: ['Type', 'Age', 'Gender', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed', 'Sterilized', 'Health', 'Fee', 'VideoAmt', 'PhotoAmt', 'FinalBreed', 'ColorDiversity', 'Fully_Healthy', 'desc_length', 'sentiment_vader', 'positive_kw', 'negative_kw', 'keyword_sentiment']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>FurLength</th>\n",
       "      <th>Vaccinated</th>\n",
       "      <th>Dewormed</th>\n",
       "      <th>Sterilized</th>\n",
       "      <th>Health</th>\n",
       "      <th>Fee</th>\n",
       "      <th>...</th>\n",
       "      <th>clip_text_pca_40</th>\n",
       "      <th>clip_text_pca_41</th>\n",
       "      <th>clip_text_pca_42</th>\n",
       "      <th>clip_text_pca_43</th>\n",
       "      <th>clip_text_pca_44</th>\n",
       "      <th>clip_text_pca_45</th>\n",
       "      <th>clip_text_pca_46</th>\n",
       "      <th>clip_text_pca_47</th>\n",
       "      <th>clip_text_pca_48</th>\n",
       "      <th>clip_text_pca_49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076847</td>\n",
       "      <td>0.187917</td>\n",
       "      <td>0.052599</td>\n",
       "      <td>0.309394</td>\n",
       "      <td>-0.169841</td>\n",
       "      <td>-0.041322</td>\n",
       "      <td>-0.013239</td>\n",
       "      <td>-0.225467</td>\n",
       "      <td>-0.115706</td>\n",
       "      <td>-0.025613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024820</td>\n",
       "      <td>-0.288663</td>\n",
       "      <td>-0.103171</td>\n",
       "      <td>-0.355694</td>\n",
       "      <td>-0.154380</td>\n",
       "      <td>0.102484</td>\n",
       "      <td>0.385159</td>\n",
       "      <td>0.319945</td>\n",
       "      <td>-0.363156</td>\n",
       "      <td>-0.240386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177801</td>\n",
       "      <td>-0.320696</td>\n",
       "      <td>0.255823</td>\n",
       "      <td>0.240490</td>\n",
       "      <td>-0.021647</td>\n",
       "      <td>-0.083050</td>\n",
       "      <td>0.378852</td>\n",
       "      <td>-0.236843</td>\n",
       "      <td>-0.333081</td>\n",
       "      <td>-0.241618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.313598</td>\n",
       "      <td>-0.060633</td>\n",
       "      <td>-0.190628</td>\n",
       "      <td>0.097340</td>\n",
       "      <td>0.015878</td>\n",
       "      <td>0.357949</td>\n",
       "      <td>0.165794</td>\n",
       "      <td>0.625520</td>\n",
       "      <td>0.091371</td>\n",
       "      <td>-0.015644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.084076</td>\n",
       "      <td>0.285581</td>\n",
       "      <td>-0.061182</td>\n",
       "      <td>0.199514</td>\n",
       "      <td>0.067879</td>\n",
       "      <td>0.008248</td>\n",
       "      <td>0.119003</td>\n",
       "      <td>0.264303</td>\n",
       "      <td>0.108563</td>\n",
       "      <td>0.073413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type  Age  Gender  MaturitySize  FurLength  Vaccinated  Dewormed  \\\n",
       "0     2    3       1             1          1           2         2   \n",
       "1     2    1       1             2          2           3         3   \n",
       "2     1    1       1             2          2           1         1   \n",
       "3     1    4       2             2          1           1         1   \n",
       "4     1    1       1             2          1           2         2   \n",
       "\n",
       "   Sterilized  Health  Fee  ...  clip_text_pca_40  clip_text_pca_41  \\\n",
       "0           2       1  100  ...          0.076847          0.187917   \n",
       "1           3       1    0  ...         -0.024820         -0.288663   \n",
       "2           2       1    0  ...          0.177801         -0.320696   \n",
       "3           2       1  150  ...         -0.313598         -0.060633   \n",
       "4           2       1    0  ...         -0.084076          0.285581   \n",
       "\n",
       "   clip_text_pca_42  clip_text_pca_43  clip_text_pca_44  clip_text_pca_45  \\\n",
       "0          0.052599          0.309394         -0.169841         -0.041322   \n",
       "1         -0.103171         -0.355694         -0.154380          0.102484   \n",
       "2          0.255823          0.240490         -0.021647         -0.083050   \n",
       "3         -0.190628          0.097340          0.015878          0.357949   \n",
       "4         -0.061182          0.199514          0.067879          0.008248   \n",
       "\n",
       "   clip_text_pca_46  clip_text_pca_47  clip_text_pca_48  clip_text_pca_49  \n",
       "0         -0.013239         -0.225467         -0.115706         -0.025613  \n",
       "1          0.385159          0.319945         -0.363156         -0.240386  \n",
       "2          0.378852         -0.236843         -0.333081         -0.241618  \n",
       "3          0.165794          0.625520          0.091371         -0.015644  \n",
       "4          0.119003          0.264303          0.108563          0.073413  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================\n",
    "# 4. BUILD X, y\n",
    "# ============================================\n",
    "\n",
    "target_col = \"AdoptionSpeed\"\n",
    "\n",
    "# Keep PetID for record-keeping / fusion\n",
    "pet_ids = df[\"PetID\"].copy()\n",
    "\n",
    "# String / label columns to drop from features\n",
    "string_drop_cols = [\n",
    "    \"Breed1Name\",\n",
    "    \"Breed2Name\",\n",
    "    \"Color1Name\",\n",
    "    \"Color2Name\",\n",
    "    \"Color3Name\",\n",
    "    \"StateName\",\n",
    "    \"lang\"           # language code is string\n",
    "]\n",
    "\n",
    "# Non-feature columns\n",
    "raw_drop_cols = [\n",
    "    target_col,\n",
    "    \"Description\",\n",
    "    \"Description_en\",\n",
    "    \"PetID\",\n",
    "    \"Name\",\n",
    "    \"RescuerID\",\n",
    "    \"desc_clean\"\n",
    "]\n",
    "\n",
    "# Only drop columns that exist\n",
    "drop_cols = [c for c in (string_drop_cols + raw_drop_cols) if c in df.columns]\n",
    "\n",
    "y = df[target_col]\n",
    "X = df.drop(columns=drop_cols)\n",
    "\n",
    "# Keep only numeric columns\n",
    "X = X.select_dtypes(include=[\"number\"])\n",
    "\n",
    "print(\"Final X shape:\", X.shape)\n",
    "print(\"First 20 feature columns:\", X.columns[:20].tolist())\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676d0348",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1aae82a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Fold 1 ----\n",
      "\n",
      "---- Fold 2 ----\n",
      "\n",
      "---- Fold 3 ----\n",
      "\n",
      "---- Fold 4 ----\n",
      "\n",
      "---- Fold 5 ----\n",
      "\n",
      "===== 5-Fold CV Results (XGBoost) =====\n",
      "Accuracy: 0.42888024210981407 +/- 0.006021784815038526\n",
      "Macro F1: 0.3541064980734946 +/- 0.009967433390739031\n",
      "QWK    : 0.37587070800339395 +/- 0.01458101897852299\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 5. 5-FOLD STRATIFIED CROSS-VALIDATION (XGBOOST)\n",
    "# ============================================\n",
    "\n",
    "X_all = X.to_numpy(dtype=np.float32)\n",
    "y_all = y.to_numpy()\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "acc_scores, f1_scores, qwk_scores = [], [], []\n",
    "\n",
    "fold = 1\n",
    "for train_idx, val_idx in skf.split(X_all, y_all):\n",
    "    print(f\"\\n---- Fold {fold} ----\")\n",
    "    fold += 1\n",
    "    \n",
    "    X_tr, X_va = X_all[train_idx], X_all[val_idx]\n",
    "    y_tr, y_va = y_all[train_idx], y_all[val_idx]\n",
    "    \n",
    "    xgb_cv = XGBClassifier(\n",
    "        n_estimators=350,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        min_child_weight=3,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        reg_lambda=1.0,\n",
    "        objective=\"multi:softprob\",\n",
    "        num_class=5,\n",
    "        eval_metric=\"mlogloss\",\n",
    "        tree_method=\"hist\",\n",
    "        nthread=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    xgb_cv.fit(X_tr, y_tr)\n",
    "    preds = np.argmax(xgb_cv.predict_proba(X_va), axis=1)\n",
    "    \n",
    "    acc_scores.append(accuracy_score(y_va, preds))\n",
    "    f1_scores.append(f1_score(y_va, preds, average=\"macro\"))\n",
    "    qwk_scores.append(cohen_kappa_score(y_va, preds, weights=\"quadratic\"))\n",
    "\n",
    "print(\"\\n===== 5-Fold CV Results (XGBoost) =====\")\n",
    "print(\"Accuracy:\", np.mean(acc_scores), \"+/-\", np.std(acc_scores))\n",
    "print(\"Macro F1:\", np.mean(f1_scores), \"+/-\", np.std(f1_scores))\n",
    "print(\"QWK    :\", np.mean(qwk_scores), \"+/-\", np.std(qwk_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1964cac",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18e73b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (9252, 71)\n",
      "Val shape  : (2313, 71)\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 6. TRAIN/VAL SPLIT (80/20) WITH PetID\n",
    "# ============================================\n",
    "\n",
    "X_train, X_val, y_train, y_val, petid_train, petid_val = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    pet_ids,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Val shape  :\", X_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33ba3540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 7. SCALE FEATURES FOR MLP\n",
    "# ============================================\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled   = scaler.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2de69e4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c6f92d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DecisionTree ===\n",
      "Accuracy   : 0.3316\n",
      "Macro F1   : 0.2798\n",
      "QWK        : 0.1927\n",
      "\n",
      "=== RandomForest ===\n",
      "Accuracy   : 0.4475\n",
      "Macro F1   : 0.3648\n",
      "QWK        : 0.4034\n",
      "\n",
      "=== XGBoost ===\n",
      "Accuracy   : 0.4328\n",
      "Macro F1   : 0.3701\n",
      "QWK        : 0.3903\n",
      "0:\tlearn: 0.2077584\ttotal: 33.4ms\tremaining: 13.3s\n",
      "100:\tlearn: 0.3617501\ttotal: 1.86s\tremaining: 5.5s\n",
      "200:\tlearn: 0.4299498\ttotal: 3.63s\tremaining: 3.59s\n",
      "300:\tlearn: 0.4915156\ttotal: 5.36s\tremaining: 1.76s\n",
      "399:\tlearn: 0.5441593\ttotal: 7.09s\tremaining: 0us\n",
      "\n",
      "=== CatBoost ===\n",
      "Accuracy   : 0.4306\n",
      "Macro F1   : 0.3351\n",
      "QWK        : 0.3732\n",
      "\n",
      "=== MLP ===\n",
      "Accuracy   : 0.3692\n",
      "Macro F1   : 0.3029\n",
      "QWK        : 0.2751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\conno\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 8. TRAIN BASELINE MODELS\n",
    "# ============================================\n",
    "\n",
    "results = []\n",
    "\n",
    "# --- Decision Tree ---\n",
    "dt_clf = DecisionTreeClassifier(\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    random_state=42\n",
    ")\n",
    "dt_clf.fit(X_train, y_train)\n",
    "y_pred_dt = dt_clf.predict(X_val)\n",
    "results.append(evaluate_model(\"DecisionTree\", y_val, y_pred_dt))\n",
    "\n",
    "# --- Random Forest ---\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_val)\n",
    "results.append(evaluate_model(\"RandomForest\", y_val, y_pred_rf))\n",
    "\n",
    "# --- XGBoost (tuned) ---\n",
    "X_train_np = X_train.to_numpy(dtype=np.float32)\n",
    "X_val_np   = X_val.to_numpy(dtype=np.float32)\n",
    "y_train_np = y_train.to_numpy()\n",
    "y_val_np   = y_val.to_numpy()\n",
    "\n",
    "xgb_clf = XGBClassifier(\n",
    "    n_estimators=350,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    min_child_weight=3,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    reg_lambda=1.0,\n",
    "    reg_alpha=0.0,\n",
    "    objective=\"multi:softprob\",\n",
    "    num_class=5,\n",
    "    eval_metric=\"mlogloss\",\n",
    "    tree_method=\"hist\",\n",
    "    nthread=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_clf.fit(X_train_np, y_train_np)\n",
    "xgb_proba = xgb_clf.predict_proba(X_val_np)\n",
    "y_pred_xgb = np.argmax(xgb_proba, axis=1).astype(int)\n",
    "results.append(evaluate_model(\"XGBoost\", y_val, y_pred_xgb))\n",
    "\n",
    "# --- CatBoost (numeric-only, tuned) ---\n",
    "cb_clf = CatBoostClassifier(\n",
    "    iterations=400,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    l2_leaf_reg=5.0,\n",
    "    loss_function=\"MultiClass\",\n",
    "    eval_metric=\"TotalF1:average=Macro\",\n",
    "    random_seed=42,\n",
    "    verbose=100,\n",
    "    od_type=\"Iter\",\n",
    "    od_wait=40\n",
    ")\n",
    "\n",
    "cb_clf.fit(X_train_np, y_train_np)\n",
    "cb_proba = cb_clf.predict_proba(X_val_np)\n",
    "y_pred_cb = np.argmax(cb_proba, axis=1).astype(int)\n",
    "results.append(evaluate_model(\"CatBoost\", y_val, y_pred_cb))\n",
    "\n",
    "# --- MLP (shallow neural net) ---\n",
    "mlp_clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(128,),\n",
    "    activation=\"relu\",\n",
    "    solver=\"adam\",\n",
    "    batch_size=128,\n",
    "    learning_rate_init=0.001,\n",
    "    max_iter=50,\n",
    "    random_state=42\n",
    ")\n",
    "mlp_clf.fit(X_train_scaled, y_train)\n",
    "mlp_proba = mlp_clf.predict_proba(X_val_scaled)\n",
    "y_pred_mlp = np.argmax(mlp_proba, axis=1).astype(int)\n",
    "results.append(evaluate_model(\"MLP\", y_val, y_pred_mlp))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed986a1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cef1a7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha=0.5, QWK=0.3949\n",
      "alpha=0.6, QWK=0.4007\n",
      "alpha=0.7, QWK=0.3962\n",
      "alpha=0.8, QWK=0.3951\n",
      "alpha=0.9, QWK=0.3871\n",
      "\n",
      "=== WeightedEnsemble_XGB_CB_alpha_0.6 ===\n",
      "Accuracy   : 0.4440\n",
      "Macro F1   : 0.3677\n",
      "QWK        : 0.4007\n",
      "\n",
      "Best weighted ensemble alpha: 0.6, QWK=0.4007\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 9. WEIGHTED SOFT ENSEMBLE: XGB + CATBOOST\n",
    "# ============================================\n",
    "\n",
    "alphas = [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "best_qwk = -1\n",
    "best_alpha = None\n",
    "best_pred = None\n",
    "\n",
    "for a in alphas:\n",
    "    blended = a * xgb_proba + (1 - a) * cb_proba\n",
    "    blended_pred = np.argmax(blended, axis=1).astype(int)\n",
    "    qwk = quadratic_weighted_kappa(y_val, blended_pred)\n",
    "    print(f\"alpha={a:.1f}, QWK={qwk:.4f}\")\n",
    "    \n",
    "    if qwk > best_qwk:\n",
    "        best_qwk = qwk\n",
    "        best_alpha = a\n",
    "        best_pred = blended_pred\n",
    "\n",
    "results.append(\n",
    "    evaluate_model(f\"WeightedEnsemble_XGB_CB_alpha_{best_alpha:.1f}\", y_val, best_pred)\n",
    ")\n",
    "\n",
    "print(f\"\\nBest weighted ensemble alpha: {best_alpha}, QWK={best_qwk:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b872068e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21e416ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>qwk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.447471</td>\n",
       "      <td>0.364817</td>\n",
       "      <td>0.403379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_XGB_CB_alpha_0.6</td>\n",
       "      <td>0.444012</td>\n",
       "      <td>0.367681</td>\n",
       "      <td>0.400667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.432771</td>\n",
       "      <td>0.370134</td>\n",
       "      <td>0.390340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.430610</td>\n",
       "      <td>0.335062</td>\n",
       "      <td>0.373210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.369217</td>\n",
       "      <td>0.302893</td>\n",
       "      <td>0.275054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.331604</td>\n",
       "      <td>0.279840</td>\n",
       "      <td>0.192715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               model  accuracy  macro_f1       qwk\n",
       "0                       RandomForest  0.447471  0.364817  0.403379\n",
       "1  WeightedEnsemble_XGB_CB_alpha_0.6  0.444012  0.367681  0.400667\n",
       "2                            XGBoost  0.432771  0.370134  0.390340\n",
       "3                           CatBoost  0.430610  0.335062  0.373210\n",
       "4                                MLP  0.369217  0.302893  0.275054\n",
       "5                       DecisionTree  0.331604  0.279840  0.192715"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================\n",
    "# 10. LEADERBOARD\n",
    "# ============================================\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by=\"qwk\", ascending=False).reset_index(drop=True)\n",
    "results_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
